{"cells":[{"cell_type":"markdown","source":["For help, look here:\nhttps://spark.apache.org/docs/latest/rdd-programming-guide.html"],"metadata":{}},{"cell_type":"code","source":["# Check out pre-loaded dataset\ndisplay(dbutils.fs.ls('dbfs:/'))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/</td><td>FileStore/</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/</td><td>databricks-datasets/</td><td>0</td></tr><tr><td>dbfs:/databricks-results/</td><td>databricks-results/</td><td>0</td></tr><tr><td>dbfs:/tmp/</td><td>tmp/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Create a rdd (sc = SparkContext)\nrdd = sc.textFile(\"dbfs:/databricks-datasets/SPARK_README.md\")"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Read 20 lines \nrdd.take(20)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[107]: [&#39;# Apache Spark&#39;,\n &#39;&#39;,\n &#39;Spark is a fast and general cluster computing system for Big Data. It provides&#39;,\n &#39;high-level APIs in Scala, Java, Python, and R, and an optimized engine that&#39;,\n &#39;supports general computation graphs for data analysis. It also supports a&#39;,\n &#39;rich set of higher-level tools including Spark SQL for SQL and DataFrames,&#39;,\n &#39;MLlib for machine learning, GraphX for graph processing,&#39;,\n &#39;and Spark Streaming for stream processing.&#39;,\n &#39;&#39;,\n &#39;&lt;http://spark.apache.org/&gt;&#39;,\n &#39;&#39;,\n &#39;&#39;,\n &#39;## Online Documentation&#39;,\n &#39;&#39;,\n &#39;You can find the latest Spark documentation, including a programming&#39;,\n &#39;guide, on the [project web page](http://spark.apache.org/documentation.html)&#39;,\n &#39;and [project wiki](https://cwiki.apache.org/confluence/display/SPARK).&#39;,\n &#39;This README file only contains basic setup instructions.&#39;,\n &#39;&#39;,\n &#39;## Building Spark&#39;]</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Example: lambda functions  \nwords = rdd.flatMap(lambda lines: lines.split(\" \"))\nwords.take(10)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[108]: [&#39;#&#39;, &#39;Apache&#39;, &#39;Spark&#39;, &#39;&#39;, &#39;Spark&#39;, &#39;is&#39;, &#39;a&#39;, &#39;fast&#39;, &#39;and&#39;, &#39;general&#39;]</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Take the previous function and\n# 1. count all the words\nwordCounts = words.map(lambda x: (x, 1))\\\n                  .reduceByKey(lambda x,y: x + y)\n\nfor w in wordCounts.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;#&#39;, 1)\n(&#39;Apache&#39;, 1)\n(&#39;Spark&#39;, 13)\n(&#39;&#39;, 67)\n(&#39;is&#39;, 6)\n(&#39;It&#39;, 2)\n(&#39;provides&#39;, 1)\n(&#39;high-level&#39;, 1)\n(&#39;APIs&#39;, 1)\n(&#39;in&#39;, 5)\n(&#39;Scala,&#39;, 1)\n(&#39;Java,&#39;, 1)\n(&#39;an&#39;, 3)\n(&#39;optimized&#39;, 1)\n(&#39;engine&#39;, 1)\n(&#39;supports&#39;, 2)\n(&#39;computation&#39;, 1)\n(&#39;analysis.&#39;, 1)\n(&#39;set&#39;, 2)\n(&#39;of&#39;, 5)\n(&#39;tools&#39;, 1)\n(&#39;SQL&#39;, 2)\n(&#39;MLlib&#39;, 1)\n(&#39;machine&#39;, 1)\n(&#39;learning,&#39;, 1)\n(&#39;GraphX&#39;, 1)\n(&#39;graph&#39;, 1)\n(&#39;processing,&#39;, 1)\n(&#39;Documentation&#39;, 1)\n(&#39;latest&#39;, 1)\n(&#39;programming&#39;, 1)\n(&#39;guide,&#39;, 1)\n(&#39;[project&#39;, 2)\n(&#39;README&#39;, 1)\n(&#39;only&#39;, 1)\n(&#39;basic&#39;, 1)\n(&#39;instructions.&#39;, 1)\n(&#39;Building&#39;, 1)\n(&#39;using&#39;, 2)\n(&#39;[Apache&#39;, 1)\n(&#39;run:&#39;, 1)\n(&#39;do&#39;, 2)\n(&#39;this&#39;, 1)\n(&#39;downloaded&#39;, 1)\n(&#39;documentation&#39;, 3)\n(&#39;project&#39;, 1)\n(&#39;site,&#39;, 1)\n(&#39;at&#39;, 2)\n(&#39;Spark&#34;](http://spark.apache.org/docs/latest/building-spark.html).&#39;, 1)\n(&#39;Interactive&#39;, 2)\n(&#39;Shell&#39;, 2)\n(&#39;The&#39;, 1)\n(&#39;way&#39;, 1)\n(&#39;start&#39;, 1)\n(&#39;Try&#39;, 1)\n(&#39;following&#39;, 2)\n(&#39;1000:&#39;, 2)\n(&#39;scala&gt;&#39;, 1)\n(&#39;1000).count()&#39;, 1)\n(&#39;Python&#39;, 2)\n(&#39;Alternatively,&#39;, 1)\n(&#39;use&#39;, 3)\n(&#39;And&#39;, 1)\n(&#39;run&#39;, 7)\n(&#39;Example&#39;, 1)\n(&#39;several&#39;, 1)\n(&#39;programs&#39;, 2)\n(&#39;them,&#39;, 1)\n(&#39;`./bin/run-example&#39;, 1)\n(&#39;[params]`.&#39;, 1)\n(&#39;example:&#39;, 1)\n(&#39;./bin/run-example&#39;, 2)\n(&#39;SparkPi&#39;, 2)\n(&#39;variable&#39;, 1)\n(&#39;when&#39;, 1)\n(&#39;examples&#39;, 2)\n(&#39;spark://&#39;, 1)\n(&#39;URL,&#39;, 1)\n(&#39;YARN,&#39;, 1)\n(&#39;&#34;local&#34;&#39;, 1)\n(&#39;locally&#39;, 2)\n(&#39;N&#39;, 1)\n(&#39;abbreviated&#39;, 1)\n(&#39;class&#39;, 2)\n(&#39;name&#39;, 1)\n(&#39;package.&#39;, 1)\n(&#39;instance:&#39;, 1)\n(&#39;print&#39;, 1)\n(&#39;usage&#39;, 1)\n(&#39;help&#39;, 1)\n(&#39;no&#39;, 1)\n(&#39;params&#39;, 1)\n(&#39;are&#39;, 1)\n(&#39;Testing&#39;, 1)\n(&#39;Spark](#building-spark).&#39;, 1)\n(&#39;Once&#39;, 1)\n(&#39;built,&#39;, 1)\n(&#39;tests&#39;, 2)\n(&#39;using:&#39;, 1)\n(&#39;./dev/run-tests&#39;, 1)\n(&#39;Please&#39;, 3)\n(&#39;guidance&#39;, 2)\n(&#39;module,&#39;, 1)\n(&#39;individual&#39;, 1)\n(&#39;Note&#39;, 1)\n(&#39;About&#39;, 1)\n(&#39;uses&#39;, 1)\n(&#39;library&#39;, 1)\n(&#39;HDFS&#39;, 1)\n(&#39;other&#39;, 1)\n(&#39;Hadoop-supported&#39;, 1)\n(&#39;storage&#39;, 1)\n(&#39;systems.&#39;, 1)\n(&#39;Because&#39;, 1)\n(&#39;have&#39;, 1)\n(&#39;changed&#39;, 1)\n(&#39;different&#39;, 1)\n(&#39;versions&#39;, 1)\n(&#39;Hadoop,&#39;, 2)\n(&#39;must&#39;, 1)\n(&#39;against&#39;, 1)\n(&#39;version&#39;, 1)\n(&#39;refer&#39;, 2)\n(&#39;particular&#39;, 2)\n(&#39;distribution&#39;, 1)\n(&#39;Hive&#39;, 2)\n(&#39;Thriftserver&#39;, 1)\n(&#39;distributions.&#39;, 1)\n(&#39;[Configuration&#39;, 1)\n(&#39;Guide](http://spark.apache.org/docs/latest/configuration.html)&#39;, 1)\n(&#39;online&#39;, 1)\n(&#39;overview&#39;, 1)\n(&#39;configure&#39;, 1)\n(&#39;Spark.&#39;, 1)\n(&#39;a&#39;, 8)\n(&#39;fast&#39;, 1)\n(&#39;and&#39;, 10)\n(&#39;general&#39;, 2)\n(&#39;cluster&#39;, 2)\n(&#39;computing&#39;, 1)\n(&#39;system&#39;, 1)\n(&#39;for&#39;, 11)\n(&#39;Big&#39;, 1)\n(&#39;Data.&#39;, 1)\n(&#39;Python,&#39;, 2)\n(&#39;R,&#39;, 1)\n(&#39;that&#39;, 2)\n(&#39;graphs&#39;, 1)\n(&#39;data&#39;, 1)\n(&#39;also&#39;, 4)\n(&#39;rich&#39;, 1)\n(&#39;higher-level&#39;, 1)\n(&#39;including&#39;, 3)\n(&#39;DataFrames,&#39;, 1)\n(&#39;Streaming&#39;, 1)\n(&#39;stream&#39;, 1)\n(&#39;processing.&#39;, 1)\n(&#39;&lt;http://spark.apache.org/&gt;&#39;, 1)\n(&#39;##&#39;, 8)\n(&#39;Online&#39;, 1)\n(&#39;You&#39;, 3)\n(&#39;can&#39;, 6)\n(&#39;find&#39;, 1)\n(&#39;the&#39;, 21)\n(&#39;documentation,&#39;, 1)\n(&#39;on&#39;, 5)\n(&#39;web&#39;, 1)\n(&#39;page](http://spark.apache.org/documentation.html)&#39;, 1)\n(&#39;wiki](https://cwiki.apache.org/confluence/display/SPARK).&#39;, 1)\n(&#39;This&#39;, 2)\n(&#39;file&#39;, 1)\n(&#39;contains&#39;, 1)\n(&#39;setup&#39;, 1)\n(&#39;built&#39;, 1)\n(&#39;Maven](http://maven.apache.org/).&#39;, 1)\n(&#39;To&#39;, 2)\n(&#39;build&#39;, 3)\n(&#39;its&#39;, 1)\n(&#39;example&#39;, 3)\n(&#39;programs,&#39;, 1)\n(&#39;build/mvn&#39;, 1)\n(&#39;-DskipTests&#39;, 1)\n(&#39;clean&#39;, 1)\n(&#39;package&#39;, 1)\n(&#39;(You&#39;, 1)\n(&#39;not&#39;, 1)\n(&#39;need&#39;, 1)\n(&#39;to&#39;, 14)\n(&#39;if&#39;, 4)\n(&#39;you&#39;, 4)\n(&#39;pre-built&#39;, 1)\n(&#39;package.)&#39;, 1)\n(&#39;More&#39;, 1)\n(&#39;detailed&#39;, 2)\n(&#39;available&#39;, 1)\n(&#39;from&#39;, 1)\n(&#39;[&#34;Building&#39;, 1)\n(&#39;Scala&#39;, 2)\n(&#39;easiest&#39;, 1)\n(&#39;through&#39;, 1)\n(&#39;shell:&#39;, 2)\n(&#39;./bin/spark-shell&#39;, 1)\n(&#39;command,&#39;, 2)\n(&#39;which&#39;, 2)\n(&#39;should&#39;, 2)\n(&#39;return&#39;, 2)\n(&#39;sc.parallelize(1&#39;, 1)\n(&#39;prefer&#39;, 1)\n(&#39;./bin/pyspark&#39;, 1)\n(&#39;&gt;&gt;&gt;&#39;, 1)\n(&#39;sc.parallelize(range(1000)).count()&#39;, 1)\n(&#39;Programs&#39;, 1)\n(&#39;comes&#39;, 1)\n(&#39;with&#39;, 3)\n(&#39;sample&#39;, 1)\n(&#39;`examples`&#39;, 2)\n(&#39;directory.&#39;, 1)\n(&#39;one&#39;, 2)\n(&#39;&lt;class&gt;&#39;, 1)\n(&#39;For&#39;, 2)\n(&#39;will&#39;, 1)\n(&#39;Pi&#39;, 1)\n(&#39;locally.&#39;, 1)\n(&#39;MASTER&#39;, 1)\n(&#39;environment&#39;, 1)\n(&#39;running&#39;, 1)\n(&#39;submit&#39;, 1)\n(&#39;cluster.&#39;, 1)\n(&#39;be&#39;, 2)\n(&#39;mesos://&#39;, 1)\n(&#39;or&#39;, 3)\n(&#39;&#34;yarn&#34;&#39;, 1)\n(&#39;thread,&#39;, 1)\n(&#39;&#34;local[N]&#34;&#39;, 1)\n(&#39;threads.&#39;, 1)\n(&#39;MASTER=spark://host:7077&#39;, 1)\n(&#39;Many&#39;, 1)\n(&#39;given.&#39;, 1)\n(&#39;Running&#39;, 1)\n(&#39;Tests&#39;, 1)\n(&#39;first&#39;, 1)\n(&#39;requires&#39;, 1)\n(&#39;[building&#39;, 1)\n(&#39;see&#39;, 1)\n(&#39;how&#39;, 2)\n(&#39;[run&#39;, 1)\n(&#39;tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).&#39;, 1)\n(&#39;A&#39;, 1)\n(&#39;Hadoop&#39;, 3)\n(&#39;Versions&#39;, 1)\n(&#39;core&#39;, 1)\n(&#39;talk&#39;, 1)\n(&#39;protocols&#39;, 1)\n(&#39;same&#39;, 1)\n(&#39;your&#39;, 1)\n(&#39;runs.&#39;, 1)\n(&#39;[&#34;Specifying&#39;, 1)\n(&#39;Version&#34;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)&#39;, 1)\n(&#39;building&#39;, 2)\n(&#39;Configuration&#39;, 1)\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# 2. change all capital letters to lower case\nlowerCaseWords = words.map(lambda x: x.lower())\\\n                      .map(lambda x: (x, 1))\\\n                      .reduceByKey(lambda x,y: x + y)\n\nfor w in lowerCaseWords.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;#&#39;, 1)\n(&#39;&#39;, 67)\n(&#39;is&#39;, 6)\n(&#39;data.&#39;, 1)\n(&#39;provides&#39;, 1)\n(&#39;high-level&#39;, 1)\n(&#39;in&#39;, 5)\n(&#39;java,&#39;, 1)\n(&#39;r,&#39;, 1)\n(&#39;an&#39;, 3)\n(&#39;optimized&#39;, 1)\n(&#39;engine&#39;, 1)\n(&#39;supports&#39;, 2)\n(&#39;computation&#39;, 1)\n(&#39;analysis.&#39;, 1)\n(&#39;set&#39;, 2)\n(&#39;of&#39;, 5)\n(&#39;tools&#39;, 1)\n(&#39;dataframes,&#39;, 1)\n(&#39;machine&#39;, 1)\n(&#39;learning,&#39;, 1)\n(&#39;graph&#39;, 1)\n(&#39;processing,&#39;, 1)\n(&#39;streaming&#39;, 1)\n(&#39;online&#39;, 2)\n(&#39;documentation&#39;, 4)\n(&#39;latest&#39;, 1)\n(&#39;programming&#39;, 1)\n(&#39;guide,&#39;, 1)\n(&#39;[project&#39;, 2)\n(&#39;wiki](https://cwiki.apache.org/confluence/display/spark).&#39;, 1)\n(&#39;this&#39;, 3)\n(&#39;readme&#39;, 1)\n(&#39;only&#39;, 1)\n(&#39;basic&#39;, 1)\n(&#39;instructions.&#39;, 1)\n(&#39;using&#39;, 2)\n(&#39;maven](http://maven.apache.org/).&#39;, 1)\n(&#39;run:&#39;, 1)\n(&#39;(you&#39;, 1)\n(&#39;do&#39;, 2)\n(&#39;downloaded&#39;, 1)\n(&#39;more&#39;, 1)\n(&#39;project&#39;, 1)\n(&#39;site,&#39;, 1)\n(&#39;at&#39;, 2)\n(&#39;spark&#34;](http://spark.apache.org/docs/latest/building-spark.html).&#39;, 1)\n(&#39;scala&#39;, 2)\n(&#39;shell&#39;, 2)\n(&#39;way&#39;, 1)\n(&#39;start&#39;, 1)\n(&#39;try&#39;, 1)\n(&#39;following&#39;, 2)\n(&#39;1000:&#39;, 2)\n(&#39;scala&gt;&#39;, 1)\n(&#39;1000).count()&#39;, 1)\n(&#39;python&#39;, 2)\n(&#39;alternatively,&#39;, 1)\n(&#39;use&#39;, 3)\n(&#39;run&#39;, 7)\n(&#39;programs&#39;, 3)\n(&#39;several&#39;, 1)\n(&#39;them,&#39;, 1)\n(&#39;`./bin/run-example&#39;, 1)\n(&#39;[params]`.&#39;, 1)\n(&#39;example:&#39;, 1)\n(&#39;./bin/run-example&#39;, 2)\n(&#39;master&#39;, 1)\n(&#39;variable&#39;, 1)\n(&#39;when&#39;, 1)\n(&#39;examples&#39;, 2)\n(&#39;spark://&#39;, 1)\n(&#39;url,&#39;, 1)\n(&#39;yarn,&#39;, 1)\n(&#39;&#34;local&#34;&#39;, 1)\n(&#39;locally&#39;, 2)\n(&#39;&#34;local[n]&#34;&#39;, 1)\n(&#39;abbreviated&#39;, 1)\n(&#39;class&#39;, 2)\n(&#39;name&#39;, 1)\n(&#39;package.&#39;, 1)\n(&#39;instance:&#39;, 1)\n(&#39;master=spark://host:7077&#39;, 1)\n(&#39;print&#39;, 1)\n(&#39;usage&#39;, 1)\n(&#39;help&#39;, 1)\n(&#39;no&#39;, 1)\n(&#39;params&#39;, 1)\n(&#39;are&#39;, 1)\n(&#39;tests&#39;, 3)\n(&#39;once&#39;, 1)\n(&#39;built,&#39;, 1)\n(&#39;using:&#39;, 1)\n(&#39;./dev/run-tests&#39;, 1)\n(&#39;guidance&#39;, 2)\n(&#39;module,&#39;, 1)\n(&#39;individual&#39;, 1)\n(&#39;tests](https://cwiki.apache.org/confluence/display/spark/useful+developer+tools).&#39;, 1)\n(&#39;hadoop&#39;, 3)\n(&#39;versions&#39;, 2)\n(&#39;uses&#39;, 1)\n(&#39;library&#39;, 1)\n(&#39;hdfs&#39;, 1)\n(&#39;other&#39;, 1)\n(&#39;storage&#39;, 1)\n(&#39;systems.&#39;, 1)\n(&#39;have&#39;, 1)\n(&#39;changed&#39;, 1)\n(&#39;different&#39;, 1)\n(&#39;hadoop,&#39;, 2)\n(&#39;must&#39;, 1)\n(&#39;against&#39;, 1)\n(&#39;version&#39;, 1)\n(&#39;refer&#39;, 2)\n(&#39;[&#34;specifying&#39;, 1)\n(&#39;version&#34;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)&#39;, 1)\n(&#39;particular&#39;, 2)\n(&#39;distribution&#39;, 1)\n(&#39;hive&#39;, 2)\n(&#39;distributions.&#39;, 1)\n(&#39;configuration&#39;, 1)\n(&#39;guide](http://spark.apache.org/docs/latest/configuration.html)&#39;, 1)\n(&#39;overview&#39;, 1)\n(&#39;configure&#39;, 1)\n(&#39;spark.&#39;, 1)\n(&#39;apache&#39;, 1)\n(&#39;spark&#39;, 13)\n(&#39;a&#39;, 9)\n(&#39;fast&#39;, 1)\n(&#39;and&#39;, 11)\n(&#39;general&#39;, 2)\n(&#39;cluster&#39;, 2)\n(&#39;computing&#39;, 1)\n(&#39;system&#39;, 1)\n(&#39;for&#39;, 13)\n(&#39;big&#39;, 1)\n(&#39;it&#39;, 2)\n(&#39;apis&#39;, 1)\n(&#39;scala,&#39;, 1)\n(&#39;python,&#39;, 2)\n(&#39;that&#39;, 2)\n(&#39;graphs&#39;, 1)\n(&#39;data&#39;, 1)\n(&#39;also&#39;, 4)\n(&#39;rich&#39;, 1)\n(&#39;higher-level&#39;, 1)\n(&#39;including&#39;, 3)\n(&#39;sql&#39;, 2)\n(&#39;mllib&#39;, 1)\n(&#39;graphx&#39;, 1)\n(&#39;stream&#39;, 1)\n(&#39;processing.&#39;, 1)\n(&#39;&lt;http://spark.apache.org/&gt;&#39;, 1)\n(&#39;##&#39;, 8)\n(&#39;you&#39;, 7)\n(&#39;can&#39;, 6)\n(&#39;find&#39;, 1)\n(&#39;the&#39;, 22)\n(&#39;documentation,&#39;, 1)\n(&#39;on&#39;, 5)\n(&#39;web&#39;, 1)\n(&#39;page](http://spark.apache.org/documentation.html)&#39;, 1)\n(&#39;file&#39;, 1)\n(&#39;contains&#39;, 1)\n(&#39;setup&#39;, 1)\n(&#39;building&#39;, 3)\n(&#39;built&#39;, 1)\n(&#39;[apache&#39;, 1)\n(&#39;to&#39;, 16)\n(&#39;build&#39;, 3)\n(&#39;its&#39;, 1)\n(&#39;example&#39;, 4)\n(&#39;programs,&#39;, 1)\n(&#39;build/mvn&#39;, 1)\n(&#39;-dskiptests&#39;, 1)\n(&#39;clean&#39;, 1)\n(&#39;package&#39;, 1)\n(&#39;not&#39;, 1)\n(&#39;need&#39;, 1)\n(&#39;if&#39;, 4)\n(&#39;pre-built&#39;, 1)\n(&#39;package.)&#39;, 1)\n(&#39;detailed&#39;, 2)\n(&#39;available&#39;, 1)\n(&#39;from&#39;, 1)\n(&#39;[&#34;building&#39;, 1)\n(&#39;interactive&#39;, 2)\n(&#39;easiest&#39;, 1)\n(&#39;through&#39;, 1)\n(&#39;shell:&#39;, 2)\n(&#39;./bin/spark-shell&#39;, 1)\n(&#39;command,&#39;, 2)\n(&#39;which&#39;, 2)\n(&#39;should&#39;, 2)\n(&#39;return&#39;, 2)\n(&#39;sc.parallelize(1&#39;, 1)\n(&#39;prefer&#39;, 1)\n(&#39;./bin/pyspark&#39;, 1)\n(&#39;&gt;&gt;&gt;&#39;, 1)\n(&#39;sc.parallelize(range(1000)).count()&#39;, 1)\n(&#39;comes&#39;, 1)\n(&#39;with&#39;, 3)\n(&#39;sample&#39;, 1)\n(&#39;`examples`&#39;, 2)\n(&#39;directory.&#39;, 1)\n(&#39;one&#39;, 2)\n(&#39;&lt;class&gt;&#39;, 1)\n(&#39;sparkpi&#39;, 2)\n(&#39;will&#39;, 1)\n(&#39;pi&#39;, 1)\n(&#39;locally.&#39;, 1)\n(&#39;environment&#39;, 1)\n(&#39;running&#39;, 2)\n(&#39;submit&#39;, 1)\n(&#39;cluster.&#39;, 1)\n(&#39;be&#39;, 2)\n(&#39;mesos://&#39;, 1)\n(&#39;or&#39;, 3)\n(&#39;&#34;yarn&#34;&#39;, 1)\n(&#39;thread,&#39;, 1)\n(&#39;n&#39;, 1)\n(&#39;threads.&#39;, 1)\n(&#39;many&#39;, 1)\n(&#39;given.&#39;, 1)\n(&#39;testing&#39;, 1)\n(&#39;first&#39;, 1)\n(&#39;requires&#39;, 1)\n(&#39;[building&#39;, 1)\n(&#39;spark](#building-spark).&#39;, 1)\n(&#39;please&#39;, 3)\n(&#39;see&#39;, 1)\n(&#39;how&#39;, 2)\n(&#39;[run&#39;, 1)\n(&#39;note&#39;, 1)\n(&#39;about&#39;, 1)\n(&#39;core&#39;, 1)\n(&#39;talk&#39;, 1)\n(&#39;hadoop-supported&#39;, 1)\n(&#39;because&#39;, 1)\n(&#39;protocols&#39;, 1)\n(&#39;same&#39;, 1)\n(&#39;your&#39;, 1)\n(&#39;runs.&#39;, 1)\n(&#39;thriftserver&#39;, 1)\n(&#39;[configuration&#39;, 1)\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# 3. eliminate stopwords \nstopWords = ['', '#', '##', 'and', 'to', 'in', 'the', 'a', 'an', 'for', 'on', 'is', 'of'] # define the list of stop words\n\nfilteredWords = words.filter(lambda x: x not in stopWords)\\\n                      .map(lambda x: x.lower())\\\n                      .map(lambda x: (x, 1))\\\n                      .reduceByKey(lambda x,y: x + y)\n\nfor w in filteredWords.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;data.&#39;, 1)\n(&#39;provides&#39;, 1)\n(&#39;high-level&#39;, 1)\n(&#39;java,&#39;, 1)\n(&#39;r,&#39;, 1)\n(&#39;optimized&#39;, 1)\n(&#39;engine&#39;, 1)\n(&#39;supports&#39;, 2)\n(&#39;computation&#39;, 1)\n(&#39;analysis.&#39;, 1)\n(&#39;set&#39;, 2)\n(&#39;tools&#39;, 1)\n(&#39;dataframes,&#39;, 1)\n(&#39;machine&#39;, 1)\n(&#39;learning,&#39;, 1)\n(&#39;graph&#39;, 1)\n(&#39;processing,&#39;, 1)\n(&#39;streaming&#39;, 1)\n(&#39;online&#39;, 2)\n(&#39;documentation&#39;, 4)\n(&#39;latest&#39;, 1)\n(&#39;programming&#39;, 1)\n(&#39;guide,&#39;, 1)\n(&#39;[project&#39;, 2)\n(&#39;wiki](https://cwiki.apache.org/confluence/display/spark).&#39;, 1)\n(&#39;this&#39;, 3)\n(&#39;readme&#39;, 1)\n(&#39;only&#39;, 1)\n(&#39;basic&#39;, 1)\n(&#39;instructions.&#39;, 1)\n(&#39;using&#39;, 2)\n(&#39;maven](http://maven.apache.org/).&#39;, 1)\n(&#39;run:&#39;, 1)\n(&#39;(you&#39;, 1)\n(&#39;do&#39;, 2)\n(&#39;downloaded&#39;, 1)\n(&#39;more&#39;, 1)\n(&#39;project&#39;, 1)\n(&#39;site,&#39;, 1)\n(&#39;at&#39;, 2)\n(&#39;spark&#34;](http://spark.apache.org/docs/latest/building-spark.html).&#39;, 1)\n(&#39;scala&#39;, 2)\n(&#39;shell&#39;, 2)\n(&#39;way&#39;, 1)\n(&#39;start&#39;, 1)\n(&#39;try&#39;, 1)\n(&#39;following&#39;, 2)\n(&#39;1000:&#39;, 2)\n(&#39;scala&gt;&#39;, 1)\n(&#39;1000).count()&#39;, 1)\n(&#39;python&#39;, 2)\n(&#39;alternatively,&#39;, 1)\n(&#39;use&#39;, 3)\n(&#39;run&#39;, 7)\n(&#39;programs&#39;, 3)\n(&#39;several&#39;, 1)\n(&#39;them,&#39;, 1)\n(&#39;`./bin/run-example&#39;, 1)\n(&#39;[params]`.&#39;, 1)\n(&#39;example:&#39;, 1)\n(&#39;./bin/run-example&#39;, 2)\n(&#39;master&#39;, 1)\n(&#39;variable&#39;, 1)\n(&#39;when&#39;, 1)\n(&#39;examples&#39;, 2)\n(&#39;spark://&#39;, 1)\n(&#39;url,&#39;, 1)\n(&#39;yarn,&#39;, 1)\n(&#39;&#34;local&#34;&#39;, 1)\n(&#39;locally&#39;, 2)\n(&#39;&#34;local[n]&#34;&#39;, 1)\n(&#39;abbreviated&#39;, 1)\n(&#39;class&#39;, 2)\n(&#39;name&#39;, 1)\n(&#39;package.&#39;, 1)\n(&#39;instance:&#39;, 1)\n(&#39;master=spark://host:7077&#39;, 1)\n(&#39;print&#39;, 1)\n(&#39;usage&#39;, 1)\n(&#39;help&#39;, 1)\n(&#39;no&#39;, 1)\n(&#39;params&#39;, 1)\n(&#39;are&#39;, 1)\n(&#39;tests&#39;, 3)\n(&#39;once&#39;, 1)\n(&#39;built,&#39;, 1)\n(&#39;using:&#39;, 1)\n(&#39;./dev/run-tests&#39;, 1)\n(&#39;guidance&#39;, 2)\n(&#39;module,&#39;, 1)\n(&#39;individual&#39;, 1)\n(&#39;tests](https://cwiki.apache.org/confluence/display/spark/useful+developer+tools).&#39;, 1)\n(&#39;hadoop&#39;, 3)\n(&#39;versions&#39;, 2)\n(&#39;uses&#39;, 1)\n(&#39;library&#39;, 1)\n(&#39;hdfs&#39;, 1)\n(&#39;other&#39;, 1)\n(&#39;storage&#39;, 1)\n(&#39;systems.&#39;, 1)\n(&#39;have&#39;, 1)\n(&#39;changed&#39;, 1)\n(&#39;different&#39;, 1)\n(&#39;hadoop,&#39;, 2)\n(&#39;must&#39;, 1)\n(&#39;against&#39;, 1)\n(&#39;version&#39;, 1)\n(&#39;refer&#39;, 2)\n(&#39;[&#34;specifying&#39;, 1)\n(&#39;version&#34;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)&#39;, 1)\n(&#39;particular&#39;, 2)\n(&#39;distribution&#39;, 1)\n(&#39;hive&#39;, 2)\n(&#39;distributions.&#39;, 1)\n(&#39;configuration&#39;, 1)\n(&#39;guide](http://spark.apache.org/docs/latest/configuration.html)&#39;, 1)\n(&#39;overview&#39;, 1)\n(&#39;configure&#39;, 1)\n(&#39;spark.&#39;, 1)\n(&#39;apache&#39;, 1)\n(&#39;spark&#39;, 13)\n(&#39;fast&#39;, 1)\n(&#39;general&#39;, 2)\n(&#39;cluster&#39;, 2)\n(&#39;computing&#39;, 1)\n(&#39;system&#39;, 1)\n(&#39;big&#39;, 1)\n(&#39;it&#39;, 2)\n(&#39;apis&#39;, 1)\n(&#39;scala,&#39;, 1)\n(&#39;python,&#39;, 2)\n(&#39;that&#39;, 2)\n(&#39;graphs&#39;, 1)\n(&#39;data&#39;, 1)\n(&#39;also&#39;, 4)\n(&#39;rich&#39;, 1)\n(&#39;higher-level&#39;, 1)\n(&#39;including&#39;, 3)\n(&#39;sql&#39;, 2)\n(&#39;mllib&#39;, 1)\n(&#39;graphx&#39;, 1)\n(&#39;stream&#39;, 1)\n(&#39;processing.&#39;, 1)\n(&#39;&lt;http://spark.apache.org/&gt;&#39;, 1)\n(&#39;you&#39;, 7)\n(&#39;can&#39;, 6)\n(&#39;find&#39;, 1)\n(&#39;documentation,&#39;, 1)\n(&#39;web&#39;, 1)\n(&#39;page](http://spark.apache.org/documentation.html)&#39;, 1)\n(&#39;file&#39;, 1)\n(&#39;contains&#39;, 1)\n(&#39;setup&#39;, 1)\n(&#39;building&#39;, 3)\n(&#39;built&#39;, 1)\n(&#39;[apache&#39;, 1)\n(&#39;to&#39;, 2)\n(&#39;build&#39;, 3)\n(&#39;its&#39;, 1)\n(&#39;example&#39;, 4)\n(&#39;programs,&#39;, 1)\n(&#39;build/mvn&#39;, 1)\n(&#39;-dskiptests&#39;, 1)\n(&#39;clean&#39;, 1)\n(&#39;package&#39;, 1)\n(&#39;not&#39;, 1)\n(&#39;need&#39;, 1)\n(&#39;if&#39;, 4)\n(&#39;pre-built&#39;, 1)\n(&#39;package.)&#39;, 1)\n(&#39;detailed&#39;, 2)\n(&#39;available&#39;, 1)\n(&#39;from&#39;, 1)\n(&#39;[&#34;building&#39;, 1)\n(&#39;interactive&#39;, 2)\n(&#39;the&#39;, 1)\n(&#39;easiest&#39;, 1)\n(&#39;through&#39;, 1)\n(&#39;shell:&#39;, 2)\n(&#39;./bin/spark-shell&#39;, 1)\n(&#39;command,&#39;, 2)\n(&#39;which&#39;, 2)\n(&#39;should&#39;, 2)\n(&#39;return&#39;, 2)\n(&#39;sc.parallelize(1&#39;, 1)\n(&#39;prefer&#39;, 1)\n(&#39;./bin/pyspark&#39;, 1)\n(&#39;and&#39;, 1)\n(&#39;&gt;&gt;&gt;&#39;, 1)\n(&#39;sc.parallelize(range(1000)).count()&#39;, 1)\n(&#39;comes&#39;, 1)\n(&#39;with&#39;, 3)\n(&#39;sample&#39;, 1)\n(&#39;`examples`&#39;, 2)\n(&#39;directory.&#39;, 1)\n(&#39;one&#39;, 2)\n(&#39;&lt;class&gt;&#39;, 1)\n(&#39;for&#39;, 2)\n(&#39;sparkpi&#39;, 2)\n(&#39;will&#39;, 1)\n(&#39;pi&#39;, 1)\n(&#39;locally.&#39;, 1)\n(&#39;environment&#39;, 1)\n(&#39;running&#39;, 2)\n(&#39;submit&#39;, 1)\n(&#39;cluster.&#39;, 1)\n(&#39;be&#39;, 2)\n(&#39;mesos://&#39;, 1)\n(&#39;or&#39;, 3)\n(&#39;&#34;yarn&#34;&#39;, 1)\n(&#39;thread,&#39;, 1)\n(&#39;n&#39;, 1)\n(&#39;threads.&#39;, 1)\n(&#39;many&#39;, 1)\n(&#39;given.&#39;, 1)\n(&#39;testing&#39;, 1)\n(&#39;first&#39;, 1)\n(&#39;requires&#39;, 1)\n(&#39;[building&#39;, 1)\n(&#39;spark](#building-spark).&#39;, 1)\n(&#39;please&#39;, 3)\n(&#39;see&#39;, 1)\n(&#39;how&#39;, 2)\n(&#39;[run&#39;, 1)\n(&#39;a&#39;, 1)\n(&#39;note&#39;, 1)\n(&#39;about&#39;, 1)\n(&#39;core&#39;, 1)\n(&#39;talk&#39;, 1)\n(&#39;hadoop-supported&#39;, 1)\n(&#39;because&#39;, 1)\n(&#39;protocols&#39;, 1)\n(&#39;same&#39;, 1)\n(&#39;your&#39;, 1)\n(&#39;runs.&#39;, 1)\n(&#39;thriftserver&#39;, 1)\n(&#39;[configuration&#39;, 1)\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# 4. sort in alphabetical order\nsortedWords = words.filter(lambda x: x not in stopWords)\\\n                    .map(lambda x: x.lower())\\\n                    .map(lambda x: (x, 1))\\\n                    .reduceByKey(lambda x,y: x + y)\\\n                    .sortByKey()\n\nfor w in sortedWords.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;&#34;local&#34;&#39;, 1)\n(&#39;&#34;local[n]&#34;&#39;, 1)\n(&#39;&#34;yarn&#34;&#39;, 1)\n(&#39;(you&#39;, 1)\n(&#39;-dskiptests&#39;, 1)\n(&#39;./bin/pyspark&#39;, 1)\n(&#39;./bin/run-example&#39;, 2)\n(&#39;./bin/spark-shell&#39;, 1)\n(&#39;./dev/run-tests&#39;, 1)\n(&#39;1000).count()&#39;, 1)\n(&#39;1000:&#39;, 2)\n(&#39;&lt;class&gt;&#39;, 1)\n(&#39;&lt;http://spark.apache.org/&gt;&#39;, 1)\n(&#39;&gt;&gt;&gt;&#39;, 1)\n(&#39;[&#34;building&#39;, 1)\n(&#39;[&#34;specifying&#39;, 1)\n(&#39;[apache&#39;, 1)\n(&#39;[building&#39;, 1)\n(&#39;[configuration&#39;, 1)\n(&#39;[params]`.&#39;, 1)\n(&#39;[project&#39;, 2)\n(&#39;[run&#39;, 1)\n(&#39;`./bin/run-example&#39;, 1)\n(&#39;`examples`&#39;, 2)\n(&#39;a&#39;, 1)\n(&#39;abbreviated&#39;, 1)\n(&#39;about&#39;, 1)\n(&#39;against&#39;, 1)\n(&#39;also&#39;, 4)\n(&#39;alternatively,&#39;, 1)\n(&#39;analysis.&#39;, 1)\n(&#39;and&#39;, 1)\n(&#39;apache&#39;, 1)\n(&#39;apis&#39;, 1)\n(&#39;are&#39;, 1)\n(&#39;at&#39;, 2)\n(&#39;available&#39;, 1)\n(&#39;basic&#39;, 1)\n(&#39;be&#39;, 2)\n(&#39;because&#39;, 1)\n(&#39;big&#39;, 1)\n(&#39;build&#39;, 3)\n(&#39;build/mvn&#39;, 1)\n(&#39;building&#39;, 3)\n(&#39;built&#39;, 1)\n(&#39;built,&#39;, 1)\n(&#39;can&#39;, 6)\n(&#39;changed&#39;, 1)\n(&#39;class&#39;, 2)\n(&#39;clean&#39;, 1)\n(&#39;cluster&#39;, 2)\n(&#39;cluster.&#39;, 1)\n(&#39;comes&#39;, 1)\n(&#39;command,&#39;, 2)\n(&#39;computation&#39;, 1)\n(&#39;computing&#39;, 1)\n(&#39;configuration&#39;, 1)\n(&#39;configure&#39;, 1)\n(&#39;contains&#39;, 1)\n(&#39;core&#39;, 1)\n(&#39;data&#39;, 1)\n(&#39;data.&#39;, 1)\n(&#39;dataframes,&#39;, 1)\n(&#39;detailed&#39;, 2)\n(&#39;different&#39;, 1)\n(&#39;directory.&#39;, 1)\n(&#39;distribution&#39;, 1)\n(&#39;distributions.&#39;, 1)\n(&#39;do&#39;, 2)\n(&#39;documentation&#39;, 4)\n(&#39;documentation,&#39;, 1)\n(&#39;downloaded&#39;, 1)\n(&#39;easiest&#39;, 1)\n(&#39;engine&#39;, 1)\n(&#39;environment&#39;, 1)\n(&#39;example&#39;, 4)\n(&#39;example:&#39;, 1)\n(&#39;examples&#39;, 2)\n(&#39;fast&#39;, 1)\n(&#39;file&#39;, 1)\n(&#39;find&#39;, 1)\n(&#39;first&#39;, 1)\n(&#39;following&#39;, 2)\n(&#39;for&#39;, 2)\n(&#39;from&#39;, 1)\n(&#39;general&#39;, 2)\n(&#39;given.&#39;, 1)\n(&#39;graph&#39;, 1)\n(&#39;graphs&#39;, 1)\n(&#39;graphx&#39;, 1)\n(&#39;guidance&#39;, 2)\n(&#39;guide,&#39;, 1)\n(&#39;guide](http://spark.apache.org/docs/latest/configuration.html)&#39;, 1)\n(&#39;hadoop&#39;, 3)\n(&#39;hadoop,&#39;, 2)\n(&#39;hadoop-supported&#39;, 1)\n(&#39;have&#39;, 1)\n(&#39;hdfs&#39;, 1)\n(&#39;help&#39;, 1)\n(&#39;high-level&#39;, 1)\n(&#39;higher-level&#39;, 1)\n(&#39;hive&#39;, 2)\n(&#39;how&#39;, 2)\n(&#39;if&#39;, 4)\n(&#39;including&#39;, 3)\n(&#39;individual&#39;, 1)\n(&#39;instance:&#39;, 1)\n(&#39;instructions.&#39;, 1)\n(&#39;interactive&#39;, 2)\n(&#39;it&#39;, 2)\n(&#39;its&#39;, 1)\n(&#39;java,&#39;, 1)\n(&#39;latest&#39;, 1)\n(&#39;learning,&#39;, 1)\n(&#39;library&#39;, 1)\n(&#39;locally&#39;, 2)\n(&#39;locally.&#39;, 1)\n(&#39;machine&#39;, 1)\n(&#39;many&#39;, 1)\n(&#39;master&#39;, 1)\n(&#39;master=spark://host:7077&#39;, 1)\n(&#39;maven](http://maven.apache.org/).&#39;, 1)\n(&#39;mesos://&#39;, 1)\n(&#39;mllib&#39;, 1)\n(&#39;module,&#39;, 1)\n(&#39;more&#39;, 1)\n(&#39;must&#39;, 1)\n(&#39;n&#39;, 1)\n(&#39;name&#39;, 1)\n(&#39;need&#39;, 1)\n(&#39;no&#39;, 1)\n(&#39;not&#39;, 1)\n(&#39;note&#39;, 1)\n(&#39;once&#39;, 1)\n(&#39;one&#39;, 2)\n(&#39;online&#39;, 2)\n(&#39;only&#39;, 1)\n(&#39;optimized&#39;, 1)\n(&#39;or&#39;, 3)\n(&#39;other&#39;, 1)\n(&#39;overview&#39;, 1)\n(&#39;package&#39;, 1)\n(&#39;package.&#39;, 1)\n(&#39;package.)&#39;, 1)\n(&#39;page](http://spark.apache.org/documentation.html)&#39;, 1)\n(&#39;params&#39;, 1)\n(&#39;particular&#39;, 2)\n(&#39;pi&#39;, 1)\n(&#39;please&#39;, 3)\n(&#39;pre-built&#39;, 1)\n(&#39;prefer&#39;, 1)\n(&#39;print&#39;, 1)\n(&#39;processing,&#39;, 1)\n(&#39;processing.&#39;, 1)\n(&#39;programming&#39;, 1)\n(&#39;programs&#39;, 3)\n(&#39;programs,&#39;, 1)\n(&#39;project&#39;, 1)\n(&#39;protocols&#39;, 1)\n(&#39;provides&#39;, 1)\n(&#39;python&#39;, 2)\n(&#39;python,&#39;, 2)\n(&#39;r,&#39;, 1)\n(&#39;readme&#39;, 1)\n(&#39;refer&#39;, 2)\n(&#39;requires&#39;, 1)\n(&#39;return&#39;, 2)\n(&#39;rich&#39;, 1)\n(&#39;run&#39;, 7)\n(&#39;run:&#39;, 1)\n(&#39;running&#39;, 2)\n(&#39;runs.&#39;, 1)\n(&#39;same&#39;, 1)\n(&#39;sample&#39;, 1)\n(&#39;sc.parallelize(1&#39;, 1)\n(&#39;sc.parallelize(range(1000)).count()&#39;, 1)\n(&#39;scala&#39;, 2)\n(&#39;scala,&#39;, 1)\n(&#39;scala&gt;&#39;, 1)\n(&#39;see&#39;, 1)\n(&#39;set&#39;, 2)\n(&#39;setup&#39;, 1)\n(&#39;several&#39;, 1)\n(&#39;shell&#39;, 2)\n(&#39;shell:&#39;, 2)\n(&#39;should&#39;, 2)\n(&#39;site,&#39;, 1)\n(&#39;spark&#39;, 13)\n(&#39;spark&#34;](http://spark.apache.org/docs/latest/building-spark.html).&#39;, 1)\n(&#39;spark.&#39;, 1)\n(&#39;spark://&#39;, 1)\n(&#39;spark](#building-spark).&#39;, 1)\n(&#39;sparkpi&#39;, 2)\n(&#39;sql&#39;, 2)\n(&#39;start&#39;, 1)\n(&#39;storage&#39;, 1)\n(&#39;stream&#39;, 1)\n(&#39;streaming&#39;, 1)\n(&#39;submit&#39;, 1)\n(&#39;supports&#39;, 2)\n(&#39;system&#39;, 1)\n(&#39;systems.&#39;, 1)\n(&#39;talk&#39;, 1)\n(&#39;testing&#39;, 1)\n(&#39;tests&#39;, 3)\n(&#39;tests](https://cwiki.apache.org/confluence/display/spark/useful+developer+tools).&#39;, 1)\n(&#39;that&#39;, 2)\n(&#39;the&#39;, 1)\n(&#39;them,&#39;, 1)\n(&#39;this&#39;, 3)\n(&#39;thread,&#39;, 1)\n(&#39;threads.&#39;, 1)\n(&#39;thriftserver&#39;, 1)\n(&#39;through&#39;, 1)\n(&#39;to&#39;, 2)\n(&#39;tools&#39;, 1)\n(&#39;try&#39;, 1)\n(&#39;url,&#39;, 1)\n(&#39;usage&#39;, 1)\n(&#39;use&#39;, 3)\n(&#39;uses&#39;, 1)\n(&#39;using&#39;, 2)\n(&#39;using:&#39;, 1)\n(&#39;variable&#39;, 1)\n(&#39;version&#39;, 1)\n(&#39;version&#34;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)&#39;, 1)\n(&#39;versions&#39;, 2)\n(&#39;way&#39;, 1)\n(&#39;web&#39;, 1)\n(&#39;when&#39;, 1)\n(&#39;which&#39;, 2)\n(&#39;wiki](https://cwiki.apache.org/confluence/display/spark).&#39;, 1)\n(&#39;will&#39;, 1)\n(&#39;with&#39;, 3)\n(&#39;yarn,&#39;, 1)\n(&#39;you&#39;, 7)\n(&#39;your&#39;, 1)\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# 5.** remove punctuations \nsame_words = rdd.map(lambda w: w.translate(w.maketrans(\",.!?:;[]()-/=+#\", 15*\" \"))) \\\n                .flatMap(lambda lines: lines.split()) \\\n                .map(lambda w: w.lower()) \\\n                .filter(lambda w: w not in stopWords) \\\n                .map(lambda w: (w, 1)) \\\n                .reduceByKey(lambda x, y: x + y) \\\n                .sortByKey()\n\nfor w in same_words.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;&#34;&#39;, 1)\n(&#39;&#34;building&#39;, 1)\n(&#39;&#34;local&#39;, 1)\n(&#39;&#34;local&#34;&#39;, 1)\n(&#39;&#34;specifying&#39;, 1)\n(&#39;&#34;yarn&#34;&#39;, 1)\n(&#39;1&#39;, 1)\n(&#39;1000&#39;, 4)\n(&#39;7077&#39;, 1)\n(&#39;&lt;class&gt;&#39;, 1)\n(&#39;&lt;http&#39;, 1)\n(&#39;&gt;&#39;, 1)\n(&#39;&gt;&gt;&gt;&#39;, 1)\n(&#39;`&#39;, 2)\n(&#39;`examples`&#39;, 2)\n(&#39;abbreviated&#39;, 1)\n(&#39;about&#39;, 1)\n(&#39;against&#39;, 1)\n(&#39;also&#39;, 4)\n(&#39;alternatively&#39;, 1)\n(&#39;analysis&#39;, 1)\n(&#39;apache&#39;, 10)\n(&#39;apis&#39;, 1)\n(&#39;are&#39;, 1)\n(&#39;at&#39;, 2)\n(&#39;available&#39;, 1)\n(&#39;basic&#39;, 1)\n(&#39;be&#39;, 2)\n(&#39;because&#39;, 1)\n(&#39;big&#39;, 1)\n(&#39;bin&#39;, 5)\n(&#39;build&#39;, 4)\n(&#39;building&#39;, 7)\n(&#39;built&#39;, 3)\n(&#39;can&#39;, 6)\n(&#39;changed&#39;, 1)\n(&#39;class&#39;, 2)\n(&#39;clean&#39;, 1)\n(&#39;cluster&#39;, 3)\n(&#39;comes&#39;, 1)\n(&#39;command&#39;, 2)\n(&#39;computation&#39;, 1)\n(&#39;computing&#39;, 1)\n(&#39;configuration&#39;, 3)\n(&#39;configure&#39;, 1)\n(&#39;confluence&#39;, 2)\n(&#39;contains&#39;, 1)\n(&#39;core&#39;, 1)\n(&#39;count&#39;, 2)\n(&#39;cwiki&#39;, 2)\n(&#39;data&#39;, 2)\n(&#39;dataframes&#39;, 1)\n(&#39;detailed&#39;, 2)\n(&#39;dev&#39;, 1)\n(&#39;developer&#39;, 1)\n(&#39;different&#39;, 1)\n(&#39;directory&#39;, 1)\n(&#39;display&#39;, 2)\n(&#39;distribution&#39;, 1)\n(&#39;distributions&#39;, 1)\n(&#39;do&#39;, 2)\n(&#39;docs&#39;, 3)\n(&#39;documentation&#39;, 6)\n(&#39;downloaded&#39;, 1)\n(&#39;dskiptests&#39;, 1)\n(&#39;easiest&#39;, 1)\n(&#39;engine&#39;, 1)\n(&#39;environment&#39;, 1)\n(&#39;example&#39;, 8)\n(&#39;examples&#39;, 2)\n(&#39;fast&#39;, 1)\n(&#39;file&#39;, 1)\n(&#39;find&#39;, 1)\n(&#39;first&#39;, 1)\n(&#39;following&#39;, 2)\n(&#39;from&#39;, 1)\n(&#39;general&#39;, 2)\n(&#39;given&#39;, 1)\n(&#39;graph&#39;, 1)\n(&#39;graphs&#39;, 1)\n(&#39;graphx&#39;, 1)\n(&#39;guidance&#39;, 2)\n(&#39;guide&#39;, 2)\n(&#39;hadoop&#39;, 7)\n(&#39;have&#39;, 1)\n(&#39;hdfs&#39;, 1)\n(&#39;help&#39;, 1)\n(&#39;high&#39;, 1)\n(&#39;higher&#39;, 1)\n(&#39;hive&#39;, 2)\n(&#39;host&#39;, 1)\n(&#39;how&#39;, 2)\n(&#39;html&#39;, 4)\n(&#39;http&#39;, 5)\n(&#39;https&#39;, 2)\n(&#39;if&#39;, 4)\n(&#39;including&#39;, 3)\n(&#39;individual&#39;, 1)\n(&#39;instance&#39;, 1)\n(&#39;instructions&#39;, 1)\n(&#39;interactive&#39;, 2)\n(&#39;it&#39;, 2)\n(&#39;its&#39;, 1)\n(&#39;java&#39;, 1)\n(&#39;latest&#39;, 4)\n(&#39;learning&#39;, 1)\n(&#39;level&#39;, 2)\n(&#39;library&#39;, 1)\n(&#39;locally&#39;, 3)\n(&#39;machine&#39;, 1)\n(&#39;many&#39;, 1)\n(&#39;master&#39;, 2)\n(&#39;maven&#39;, 2)\n(&#39;mesos&#39;, 1)\n(&#39;mllib&#39;, 1)\n(&#39;module&#39;, 1)\n(&#39;more&#39;, 1)\n(&#39;must&#39;, 1)\n(&#39;mvn&#39;, 1)\n(&#39;n&#39;, 2)\n(&#39;name&#39;, 1)\n(&#39;need&#39;, 1)\n(&#39;no&#39;, 1)\n(&#39;not&#39;, 1)\n(&#39;note&#39;, 1)\n(&#39;once&#39;, 1)\n(&#39;one&#39;, 2)\n(&#39;online&#39;, 2)\n(&#39;only&#39;, 1)\n(&#39;optimized&#39;, 1)\n(&#39;or&#39;, 3)\n(&#39;org&#39;, 8)\n(&#39;other&#39;, 1)\n(&#39;overview&#39;, 1)\n(&#39;package&#39;, 3)\n(&#39;page&#39;, 1)\n(&#39;parallelize&#39;, 2)\n(&#39;params&#39;, 2)\n(&#39;particular&#39;, 2)\n(&#39;pi&#39;, 1)\n(&#39;please&#39;, 3)\n(&#39;pre&#39;, 1)\n(&#39;prefer&#39;, 1)\n(&#39;print&#39;, 1)\n(&#39;processing&#39;, 2)\n(&#39;programming&#39;, 1)\n(&#39;programs&#39;, 4)\n(&#39;project&#39;, 3)\n(&#39;protocols&#39;, 1)\n(&#39;provides&#39;, 1)\n(&#39;pyspark&#39;, 1)\n(&#39;python&#39;, 4)\n(&#39;r&#39;, 1)\n(&#39;range&#39;, 1)\n(&#39;readme&#39;, 1)\n(&#39;refer&#39;, 2)\n(&#39;requires&#39;, 1)\n(&#39;return&#39;, 2)\n(&#39;rich&#39;, 1)\n(&#39;run&#39;, 13)\n(&#39;running&#39;, 2)\n(&#39;runs&#39;, 1)\n(&#39;same&#39;, 1)\n(&#39;sample&#39;, 1)\n(&#39;sc&#39;, 2)\n(&#39;scala&#39;, 3)\n(&#39;scala&gt;&#39;, 1)\n(&#39;see&#39;, 1)\n(&#39;set&#39;, 2)\n(&#39;setup&#39;, 1)\n(&#39;several&#39;, 1)\n(&#39;shell&#39;, 5)\n(&#39;should&#39;, 2)\n(&#39;site&#39;, 1)\n(&#39;spark&#39;, 28)\n(&#39;spark&#34;&#39;, 1)\n(&#39;sparkpi&#39;, 2)\n(&#39;specifying&#39;, 1)\n(&#39;sql&#39;, 2)\n(&#39;start&#39;, 1)\n(&#39;storage&#39;, 1)\n(&#39;stream&#39;, 1)\n(&#39;streaming&#39;, 1)\n(&#39;submit&#39;, 1)\n(&#39;supported&#39;, 1)\n(&#39;supports&#39;, 2)\n(&#39;system&#39;, 1)\n(&#39;systems&#39;, 1)\n(&#39;talk&#39;, 1)\n(&#39;testing&#39;, 1)\n(&#39;tests&#39;, 5)\n(&#39;that&#39;, 2)\n(&#39;them&#39;, 1)\n(&#39;this&#39;, 3)\n(&#39;thread&#39;, 1)\n(&#39;threads&#39;, 1)\n(&#39;thriftserver&#39;, 1)\n(&#39;through&#39;, 1)\n(&#39;tools&#39;, 2)\n(&#39;try&#39;, 1)\n(&#39;url&#39;, 1)\n(&#39;usage&#39;, 1)\n(&#39;use&#39;, 3)\n(&#39;useful&#39;, 1)\n(&#39;uses&#39;, 1)\n(&#39;using&#39;, 3)\n(&#39;variable&#39;, 1)\n(&#39;version&#39;, 2)\n(&#39;version&#34;&#39;, 1)\n(&#39;versions&#39;, 2)\n(&#39;way&#39;, 1)\n(&#39;web&#39;, 1)\n(&#39;when&#39;, 1)\n(&#39;which&#39;, 2)\n(&#39;wiki&#39;, 1)\n(&#39;will&#39;, 1)\n(&#39;with&#39;, 3)\n(&#39;yarn&#39;, 1)\n(&#39;you&#39;, 8)\n(&#39;your&#39;, 1)\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# 6. sort from most to least frequent word\nsortedWords_2 = words.filter(lambda x: x not in stopWords)\\\n                      .map(lambda x: x.lower())\\\n                      .map(lambda x: (x, 1))\\\n                      .reduceByKey(lambda x,y: x + y)\\\n                      .map(lambda x: (x[1], x[0])) \\\n                      .sortByKey(ascending=False)\n\nfor w in sortedWords_2.collect():\n  print(w)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(13, &#39;spark&#39;)\n(7, &#39;run&#39;)\n(7, &#39;you&#39;)\n(6, &#39;can&#39;)\n(4, &#39;documentation&#39;)\n(4, &#39;also&#39;)\n(4, &#39;example&#39;)\n(4, &#39;if&#39;)\n(3, &#39;this&#39;)\n(3, &#39;use&#39;)\n(3, &#39;programs&#39;)\n(3, &#39;tests&#39;)\n(3, &#39;hadoop&#39;)\n(3, &#39;including&#39;)\n(3, &#39;building&#39;)\n(3, &#39;build&#39;)\n(3, &#39;with&#39;)\n(3, &#39;or&#39;)\n(3, &#39;please&#39;)\n(2, &#39;supports&#39;)\n(2, &#39;set&#39;)\n(2, &#39;online&#39;)\n(2, &#39;[project&#39;)\n(2, &#39;using&#39;)\n(2, &#39;do&#39;)\n(2, &#39;at&#39;)\n(2, &#39;scala&#39;)\n(2, &#39;shell&#39;)\n(2, &#39;following&#39;)\n(2, &#39;1000:&#39;)\n(2, &#39;python&#39;)\n(2, &#39;./bin/run-example&#39;)\n(2, &#39;examples&#39;)\n(2, &#39;locally&#39;)\n(2, &#39;class&#39;)\n(2, &#39;guidance&#39;)\n(2, &#39;versions&#39;)\n(2, &#39;hadoop,&#39;)\n(2, &#39;refer&#39;)\n(2, &#39;particular&#39;)\n(2, &#39;hive&#39;)\n(2, &#39;general&#39;)\n(2, &#39;cluster&#39;)\n(2, &#39;it&#39;)\n(2, &#39;python,&#39;)\n(2, &#39;that&#39;)\n(2, &#39;sql&#39;)\n(2, &#39;to&#39;)\n(2, &#39;detailed&#39;)\n(2, &#39;interactive&#39;)\n(2, &#39;shell:&#39;)\n(2, &#39;command,&#39;)\n(2, &#39;which&#39;)\n(2, &#39;should&#39;)\n(2, &#39;return&#39;)\n(2, &#39;`examples`&#39;)\n(2, &#39;one&#39;)\n(2, &#39;for&#39;)\n(2, &#39;sparkpi&#39;)\n(2, &#39;running&#39;)\n(2, &#39;be&#39;)\n(2, &#39;how&#39;)\n(1, &#39;data.&#39;)\n(1, &#39;provides&#39;)\n(1, &#39;high-level&#39;)\n(1, &#39;java,&#39;)\n(1, &#39;r,&#39;)\n(1, &#39;optimized&#39;)\n(1, &#39;engine&#39;)\n(1, &#39;computation&#39;)\n(1, &#39;analysis.&#39;)\n(1, &#39;tools&#39;)\n(1, &#39;dataframes,&#39;)\n(1, &#39;machine&#39;)\n(1, &#39;learning,&#39;)\n(1, &#39;graph&#39;)\n(1, &#39;processing,&#39;)\n(1, &#39;streaming&#39;)\n(1, &#39;latest&#39;)\n(1, &#39;programming&#39;)\n(1, &#39;guide,&#39;)\n(1, &#39;wiki](https://cwiki.apache.org/confluence/display/spark).&#39;)\n(1, &#39;readme&#39;)\n(1, &#39;only&#39;)\n(1, &#39;basic&#39;)\n(1, &#39;instructions.&#39;)\n(1, &#39;maven](http://maven.apache.org/).&#39;)\n(1, &#39;run:&#39;)\n(1, &#39;(you&#39;)\n(1, &#39;downloaded&#39;)\n(1, &#39;more&#39;)\n(1, &#39;project&#39;)\n(1, &#39;site,&#39;)\n(1, &#39;spark&#34;](http://spark.apache.org/docs/latest/building-spark.html).&#39;)\n(1, &#39;way&#39;)\n(1, &#39;start&#39;)\n(1, &#39;try&#39;)\n(1, &#39;scala&gt;&#39;)\n(1, &#39;1000).count()&#39;)\n(1, &#39;alternatively,&#39;)\n(1, &#39;several&#39;)\n(1, &#39;them,&#39;)\n(1, &#39;`./bin/run-example&#39;)\n(1, &#39;[params]`.&#39;)\n(1, &#39;example:&#39;)\n(1, &#39;master&#39;)\n(1, &#39;variable&#39;)\n(1, &#39;when&#39;)\n(1, &#39;spark://&#39;)\n(1, &#39;url,&#39;)\n(1, &#39;yarn,&#39;)\n(1, &#39;&#34;local&#34;&#39;)\n(1, &#39;&#34;local[n]&#34;&#39;)\n(1, &#39;abbreviated&#39;)\n(1, &#39;name&#39;)\n(1, &#39;package.&#39;)\n(1, &#39;instance:&#39;)\n(1, &#39;master=spark://host:7077&#39;)\n(1, &#39;print&#39;)\n(1, &#39;usage&#39;)\n(1, &#39;help&#39;)\n(1, &#39;no&#39;)\n(1, &#39;params&#39;)\n(1, &#39;are&#39;)\n(1, &#39;once&#39;)\n(1, &#39;built,&#39;)\n(1, &#39;using:&#39;)\n(1, &#39;./dev/run-tests&#39;)\n(1, &#39;module,&#39;)\n(1, &#39;individual&#39;)\n(1, &#39;tests](https://cwiki.apache.org/confluence/display/spark/useful+developer+tools).&#39;)\n(1, &#39;uses&#39;)\n(1, &#39;library&#39;)\n(1, &#39;hdfs&#39;)\n(1, &#39;other&#39;)\n(1, &#39;storage&#39;)\n(1, &#39;systems.&#39;)\n(1, &#39;have&#39;)\n(1, &#39;changed&#39;)\n(1, &#39;different&#39;)\n(1, &#39;must&#39;)\n(1, &#39;against&#39;)\n(1, &#39;version&#39;)\n(1, &#39;[&#34;specifying&#39;)\n(1, &#39;version&#34;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)&#39;)\n(1, &#39;distribution&#39;)\n(1, &#39;distributions.&#39;)\n(1, &#39;configuration&#39;)\n(1, &#39;guide](http://spark.apache.org/docs/latest/configuration.html)&#39;)\n(1, &#39;overview&#39;)\n(1, &#39;configure&#39;)\n(1, &#39;spark.&#39;)\n(1, &#39;apache&#39;)\n(1, &#39;fast&#39;)\n(1, &#39;computing&#39;)\n(1, &#39;system&#39;)\n(1, &#39;big&#39;)\n(1, &#39;apis&#39;)\n(1, &#39;scala,&#39;)\n(1, &#39;graphs&#39;)\n(1, &#39;data&#39;)\n(1, &#39;rich&#39;)\n(1, &#39;higher-level&#39;)\n(1, &#39;mllib&#39;)\n(1, &#39;graphx&#39;)\n(1, &#39;stream&#39;)\n(1, &#39;processing.&#39;)\n(1, &#39;&lt;http://spark.apache.org/&gt;&#39;)\n(1, &#39;find&#39;)\n(1, &#39;documentation,&#39;)\n(1, &#39;web&#39;)\n(1, &#39;page](http://spark.apache.org/documentation.html)&#39;)\n(1, &#39;file&#39;)\n(1, &#39;contains&#39;)\n(1, &#39;setup&#39;)\n(1, &#39;built&#39;)\n(1, &#39;[apache&#39;)\n(1, &#39;its&#39;)\n(1, &#39;programs,&#39;)\n(1, &#39;build/mvn&#39;)\n(1, &#39;-dskiptests&#39;)\n(1, &#39;clean&#39;)\n(1, &#39;package&#39;)\n(1, &#39;not&#39;)\n(1, &#39;need&#39;)\n(1, &#39;pre-built&#39;)\n(1, &#39;package.)&#39;)\n(1, &#39;available&#39;)\n(1, &#39;from&#39;)\n(1, &#39;[&#34;building&#39;)\n(1, &#39;the&#39;)\n(1, &#39;easiest&#39;)\n(1, &#39;through&#39;)\n(1, &#39;./bin/spark-shell&#39;)\n(1, &#39;sc.parallelize(1&#39;)\n(1, &#39;prefer&#39;)\n(1, &#39;./bin/pyspark&#39;)\n(1, &#39;and&#39;)\n(1, &#39;&gt;&gt;&gt;&#39;)\n(1, &#39;sc.parallelize(range(1000)).count()&#39;)\n(1, &#39;comes&#39;)\n(1, &#39;sample&#39;)\n(1, &#39;directory.&#39;)\n(1, &#39;&lt;class&gt;&#39;)\n(1, &#39;will&#39;)\n(1, &#39;pi&#39;)\n(1, &#39;locally.&#39;)\n(1, &#39;environment&#39;)\n(1, &#39;submit&#39;)\n(1, &#39;cluster.&#39;)\n(1, &#39;mesos://&#39;)\n(1, &#39;&#34;yarn&#34;&#39;)\n(1, &#39;thread,&#39;)\n(1, &#39;n&#39;)\n(1, &#39;threads.&#39;)\n(1, &#39;many&#39;)\n(1, &#39;given.&#39;)\n(1, &#39;testing&#39;)\n(1, &#39;first&#39;)\n(1, &#39;requires&#39;)\n(1, &#39;[building&#39;)\n(1, &#39;spark](#building-spark).&#39;)\n(1, &#39;see&#39;)\n(1, &#39;[run&#39;)\n(1, &#39;a&#39;)\n(1, &#39;note&#39;)\n(1, &#39;about&#39;)\n(1, &#39;core&#39;)\n(1, &#39;talk&#39;)\n(1, &#39;hadoop-supported&#39;)\n(1, &#39;because&#39;)\n(1, &#39;protocols&#39;)\n(1, &#39;same&#39;)\n(1, &#39;your&#39;)\n(1, &#39;runs.&#39;)\n(1, &#39;thriftserver&#39;)\n(1, &#39;[configuration&#39;)\n</div>"]}}],"execution_count":11}],"metadata":{"name":"Lab1_RDD_excercises","notebookId":1650837500227930},"nbformat":4,"nbformat_minor":0}
